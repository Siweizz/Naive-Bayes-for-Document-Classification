{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Naive_Bayes_for_Document_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVZaOYFbGoLS"
      },
      "source": [
        "### Naive Bayes for Document Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hu7Fsf8GoLS"
      },
      "source": [
        "### Datasets used for the problem:\n",
        "\n",
        "20Newgroup: Can be downloaded at http://qwone.com/~jason/20Newsgroups/20news-bydate-matlab.tgz The data is composed of six files, three of them contain the test data whilethe other three have the training data. Each row of the train.data and test.data files contain thed ata listed as (docId, wordId, count). The train.label and test.label files contain the labels for each document. The class names for each class are listed in *.map files. You can also download the vocabulary for the dataset from http://qwone.com/~jason/20Newsgroups/vocabulary.txt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4TSvBPGoLT"
      },
      "source": [
        "#### Multivariate Bernoulli Model: \n",
        "The Bernoulli model for document generation entails flipping|V|coins where|V|is the size of the vocabulary. We will model the documents in the twentywebgroups dataset using the same model, and since we have twenty classes we will beworking with a multinomial class prior distribution.\n",
        "\n",
        "#### Multinomial Event Model:\n",
        "In the multinomial event model each document corresponds to independent trials from a multinomial distribution over the vocabulary. This is also known as the unigram model. For this question you will implement the Bernoulli and Multinomial Naive Bayes models for document classification, and compare their performances.\n",
        "<i>Note: Write in your code only in the place holders where you are instructed to, replacing None.<i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4ZX4QKDGoLT"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhkVJzONGbAb"
      },
      "source": [
        "# Change it to inline to show the plots\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ambcn_inKFlw",
        "outputId": "35f0ddbe-2322-45ef-dfa9-516cb6370641"
      },
      "source": [
        "# Download the file\n",
        "!wget http://qwone.com/~jason/20Newsgroups/20news-bydate-matlab.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-27 20:42:04--  http://qwone.com/~jason/20Newsgroups/20news-bydate-matlab.tgz\n",
            "Resolving qwone.com (qwone.com)... 173.48.209.137\n",
            "Connecting to qwone.com (qwone.com)|173.48.209.137|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7575962 (7.2M) [application/x-gzip]\n",
            "Saving to: ‘20news-bydate-matlab.tgz’\n",
            "\n",
            "20news-bydate-matla 100%[===================>]   7.22M  7.85MB/s    in 0.9s    \n",
            "\n",
            "2021-06-27 20:42:05 (7.85 MB/s) - ‘20news-bydate-matlab.tgz’ saved [7575962/7575962]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmaN5UkSOsxS",
        "outputId": "1e580726-365c-41ae-b2d8-9e254da05b5f"
      },
      "source": [
        "# unzip\n",
        "!tar zxvf 20news-bydate-matlab.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20news-bydate/matlab/\n",
            "20news-bydate/matlab/train.data\n",
            "20news-bydate/matlab/train.label\n",
            "20news-bydate/matlab/train.map\n",
            "20news-bydate/matlab/test.data\n",
            "20news-bydate/matlab/test.label\n",
            "20news-bydate/matlab/test.map\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a0KdrU6GoLU"
      },
      "source": [
        "### Here is the first look at your dataset and its feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui76IOXzGoLU",
        "outputId": "1ea596a8-d62e-40c7-ba23-31509954e72b"
      },
      "source": [
        "# Change DATA_DIR to the directory containing your data files\n",
        "\n",
        "DATA_DIR='20news-bydate/matlab'\n",
        "with open(os.path.join(DATA_DIR, 'train.data')) as f:\n",
        "    lines = f.readlines()\n",
        "for l in lines[:5]:\n",
        "    doc_id,word_id,word_freq = l.strip().split(' ')\n",
        "    print ('doc_id: {} word_id: {} word frequency: {}'.format(doc_id,word_id,word_freq))\n",
        "    \n",
        "with open(os.path.join(DATA_DIR, 'train.label')) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for idx,l in enumerate(lines[:5]):\n",
        "    label = l.strip()\n",
        "    ## Notice that doc_id starts at 1, not 0.\n",
        "    print ('doc_id: {} label: {}'.format(idx+1,label))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doc_id: 1 word_id: 1 word frequency: 4\n",
            "doc_id: 1 word_id: 2 word frequency: 2\n",
            "doc_id: 1 word_id: 3 word frequency: 10\n",
            "doc_id: 1 word_id: 4 word frequency: 4\n",
            "doc_id: 1 word_id: 5 word frequency: 2\n",
            "doc_id: 1 label: 1\n",
            "doc_id: 2 label: 1\n",
            "doc_id: 3 label: 1\n",
            "doc_id: 4 label: 1\n",
            "doc_id: 5 label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGhi7113GoLU"
      },
      "source": [
        "### Task\n",
        "Create a word-frequency list across the **training** documents and sort it in descending order from highest frequency to lowest frequency.  \n",
        "We will be working with vocabulary sizes of |V| $\\in$ top{100,500,1000,2500,5000,7500,10000,12500,25000,50000, All}, where “All” is using the complete vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAxi0fW2GoLV"
      },
      "source": [
        "# Start code here\n",
        "# write a function to load the training data from the directory and create a word-frequency list that\n",
        "# is sorted in descending order from highest frequency to lowest frequency.\n",
        "\n",
        "def create_word_freq_list(train_data_dir):\n",
        "    '''\n",
        "    Your word frequency list shoule be a list of tuples\n",
        "    [ (word_1_id, word_1_frequence),(word_2_id, word_2_frequence),..., ]\n",
        "    that is SORTED by word frequency\n",
        "    '''\n",
        "    word_freq_dict = {}\n",
        "\n",
        "    with open(os.path.join(train_data_dir)) as f:\n",
        "        lines = f.readlines()\n",
        "    for l in lines:\n",
        "        doc_id, word_id, word_freq = l.strip().split(' ')\n",
        "        if word_id in word_freq_dict.keys():\n",
        "            word_freq_dict[word_id] += int(word_freq)\n",
        "        else:\n",
        "            word_freq_dict[word_id] = 1\n",
        "    word_freq_list = sorted(word_freq_dict.items(), key = lambda kv:(kv[1], kv[0]))\n",
        "    word_freq_list.reverse()\n",
        "    return word_freq_list\n",
        "\n",
        "# End code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4J28FiGoLV"
      },
      "source": [
        "### Task\n",
        "Write a class for both the Bernoulli Naive-Bayes model and the Multinomial event Naive-Bayes model. The class should fit the model to the training data and evaluate the accuracy on the test data. Keep in mind to restrict the vocabulary to the selected value of |V| for both the training and test sets. Use a simple smoothing model that assigns a default frequency of 1 to each word from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCYFejI2GoLV"
      },
      "source": [
        "# Start code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Naive_Bayes:\n",
        "    def __init__(self, vsize=None, word_freq_list=None,data_dir=None,model_type = 'bernoulli'):\n",
        "        \"\"\"\n",
        "        The init function is already written for you, we pick the top vsize words from the word_freq_list\n",
        "        and restrict our vocabulary to those words. We do so by constructing a vocab2idx dict that only contain \n",
        "        the chosen words. We also init the two parameters that will be learned during training, pi and theta.\n",
        "        \n",
        "        vsize: the vocabulary size we pick\n",
        "        word_freq_list word-frequency list\n",
        "        data_dir: directory for your data\n",
        "        model_type: either 'bernoulli' or 'multinomial'\n",
        "        \"\"\"\n",
        "        self.vocab = [int(w[0]) for w in word_freq_list[:vsize]]\n",
        "        self.vocab = np.array(self.vocab)\n",
        "        self.vocab_size = vsize\n",
        "        self.vocab2idx = {w:idx for idx,w in enumerate(self.vocab)}\n",
        "        self.data_dir=data_dir\n",
        "        self.model_type = model_type\n",
        "        \n",
        "        self.pi = None\n",
        "        self.theta = None\n",
        "        \n",
        "        \n",
        "    def _doc_vectorize(self,data_dir, model_type = 'bernoulli'):\n",
        "        \"\"\"\n",
        "        Function to read the documents data from the dir and \n",
        "        pre-process the documents into a matrix of the shape (num_of_docs, vocab_size)\n",
        "        Notice that the you need to modify your code for different \n",
        "        \n",
        "        data_dir: directory for your data\n",
        "        model_type: either 'bernoulli' or 'multinomial'\n",
        "        \n",
        "        return the document vectors in a matrix of the shape (num_of_docs, vocab_size)\n",
        "        \"\"\"\n",
        "        with open(os.path.join(data_dir)) as f:\n",
        "            lines = f.readlines()\n",
        "        data = []\n",
        "\n",
        "        for l in lines:\n",
        "            doc_id, word_id, word_freq = l.strip().split(' ')\n",
        "            data.append([int(doc_id), int(word_id), int(word_freq)])\n",
        "        data = np.array(data)\n",
        "        num_of_docs = np.unique(data[:, 0]).shape[0]\n",
        "        doc_vecs = np.zeros((num_of_docs, self.vocab_size))\n",
        "\n",
        "        if model_type == 'bernoulli':\n",
        "            for i in range(num_of_docs):\n",
        "                # The data of the document i\n",
        "                data_doc_i = data[np.where(data[:, 0] == i + 1)]\n",
        "                # All the word index of the document i\n",
        "                word_doc_i = data_doc_i[:, 1]\n",
        "                mask = np.in1d(self.vocab, word_doc_i)\n",
        "                # The word index of the vocab that in the document\n",
        "                vacab_index = np.where(mask)[0]\n",
        "                # Assign 1 to the word index in the doc_vecs matrix\n",
        "                doc_vecs[i, vacab_index] = 1\n",
        "        elif model_type == 'multivariate':\n",
        "            for i in range(num_of_docs):\n",
        "                # The data of the document i\n",
        "                data_doc_i = data[np.where(data[:, 0] == i + 1)]\n",
        "                # All the word index of the document i\n",
        "                word_doc_i = data_doc_i[:, 1]\n",
        "                mask = np.in1d(self.vocab, word_doc_i)\n",
        "                # The word index of the vocab that in the document\n",
        "                vacab_index = np.where(mask)[0].astype(int)\n",
        "                # Assign frequency of the word to the doc_vec\n",
        "                for j in vacab_index:\n",
        "                    # The index of the vocab that in the data_doc_i \n",
        "                    index_of_vocab = np.where(data_doc_i[:, 1] == self.vocab[j])\n",
        "                    doc_vecs[i, j] = data_doc_i[index_of_vocab, 2]\n",
        "                #doc_vecs[i, vacab_index] = data_doc_i[word_freq_index, 2]\n",
        "        doc_vecs = np.array(doc_vecs)\n",
        "        return doc_vecs\n",
        "        \n",
        "    def _label_vectorize(self, label_dir):\n",
        "        \"\"\"\n",
        "        Function to read the labels data from the dir and pre-process (one-hot encoding)\n",
        "        the labels into a matrix of the shape (num_of_docs, num_of_class)\n",
        "        \n",
        "        data_dir: directory for your data\n",
        "        \n",
        "        return the label vectors in a matrix of the shape (num_of_docs, num_of_classes)\n",
        "        \"\"\"\n",
        "        #For this problem, we already know num_of_classes = 20\n",
        "        num_of_classes = 20\n",
        "        with open(os.path.join(label_dir)) as f:\n",
        "            lines = f.readlines()\n",
        "        data = []\n",
        "        # Read the label\n",
        "        for l in lines:\n",
        "            data.append(int(l.strip()))\n",
        "        # Create the label_vecs matrix\n",
        "        label_vecs = np.zeros((len(lines), num_of_classes))\n",
        "\n",
        "        # Assign values to the corresponding point\n",
        "        for i in range(len(lines)):\n",
        "            label_vecs[i, data[i] - 1] = 1\n",
        "        label_vecs = np.array(label_vecs)\n",
        "        return label_vecs\n",
        "        \n",
        "    def fit(self,doc_vecs,label_vecs, model_type = 'bernoulli'):\n",
        "        \"\"\"\n",
        "        Function to learn the two parameters, pi and theta, using the doc-vectors and label-vectors\n",
        "        we got.\n",
        "        \n",
        "        doc_vecs:(num_of_docs, vocab_size)\n",
        "        label_vecs:(num_of_docs, num_of_classes)\n",
        "        return:None\n",
        "        \"\"\"\n",
        "        num_docs = doc_vecs.shape[0]\n",
        "        num_class = label_vecs.shape[1]\n",
        "\n",
        "        if model_type == 'bernoulli':\n",
        "            self.pi = np.zeros(num_class)\n",
        "            self.theta = np.dot(doc_vecs.T, label_vecs) + 1\n",
        "            for i in range(num_class):\n",
        "                # class document size, for example, class 1 has 480 documents\n",
        "                class_doc_size = np.where(label_vecs[:, i] == 1)[0].shape[0]\n",
        "                self.theta[:, i] /= (class_doc_size + self.vocab_size)\n",
        "                self.pi[i] = class_doc_size / num_docs\n",
        "        elif model_type == 'multivariate':\n",
        "            self.pi = np.zeros(num_class)\n",
        "            self.theta = np.dot(doc_vecs.T, label_vecs) + 1\n",
        "            # Get the class word size\n",
        "            class_word_size = {}\n",
        "            for k in range(num_class):\n",
        "                class_word_size[k] = sum(sum(doc_vecs[np.where(label_vecs[:, k] == 1)[0], :]))\n",
        "            # Calculate theta and pi\n",
        "            for i in range(num_class):\n",
        "                # class document size, for example, class 1 has 480 documents\n",
        "                class_doc_size = np.where(label_vecs[:, i] == 1)[0].shape[0]\n",
        "                self.theta[:, i] /= (class_word_size[i] + self.vocab_size)\n",
        "                self.pi[i] = class_doc_size / num_docs\n",
        "   \n",
        "    def predict(self,doc_vecs):\n",
        "        \"\"\"\n",
        "        Function to make predictions using the two learned parameters.\n",
        "        doc_vecs:(num_of_docs, vocab_size)\n",
        "        \n",
        "        return: predictions (num_of_docs,), each element is between 0 and num_of_classes (20)\n",
        "        \"\"\"\n",
        "        log_theta = np.log(self.theta)\n",
        "\n",
        "        prob = np.dot(doc_vecs, log_theta)\n",
        "        for i in range(self.pi.shape[0]):\n",
        "            prob[:, i] = prob[:, i] + np.log(self.pi[i])\n",
        "\n",
        "        prediction = prob.argmax(axis=1)\n",
        "        return prediction\n",
        "        \n",
        "    \n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        This function should:\n",
        "            1. Load the training data and labels\n",
        "            2. vectorize the data and the labels\n",
        "            3. fit the parameters\n",
        "        \"\"\"\n",
        "        train_data_dir = os.path.join(self.data_dir, 'test.data')\n",
        "        train_doc_vecs = self._doc_vectorize(train_data_dir, self.model_type)\n",
        "        train_label_dir = os.path.join(self.data_dir, 'test.label')\n",
        "        train_label_vecs = self._label_vectorize(train_label_dir)\n",
        "        self.vocab_size = train_doc_vecs.shape[1]\n",
        "        self.fit(train_doc_vecs, train_label_vecs, model_type=self.model_type)\n",
        "    \n",
        "    def test(self):\n",
        "        \"\"\"\n",
        "        This function should:\n",
        "            1. Load the test data and labels\n",
        "            2. vectorize the data and the labels\n",
        "            3. apply the (already trained) model to the test data and get predictions\n",
        "            4. calculate and return the accuracy of the predictions\n",
        "        \"\"\"\n",
        "        # Read test doc data\n",
        "        test_data_dir = os.path.join(self.data_dir, 'train.data')\n",
        "        test_doc_vecs = self._doc_vectorize(test_data_dir, self.model_type)\n",
        "        # Read label data\n",
        "        test_labrl_dir = os.path.join(self.data_dir, 'train.label')\n",
        "        test_labels = self._label_vectorize(test_labrl_dir)\n",
        "        test_labels = test_labels.argmax(axis=1)\n",
        "        test_predictions = self.predict(test_doc_vecs)\n",
        "        acc = np.sum(test_labels == test_predictions) / len(test_labels)\n",
        "        #print(acc)\n",
        "        return acc\n",
        "\n",
        "#End code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhq8HLUUGoLY"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtNECZa2GoLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f67335b-3cd0-456c-db85-2d59453896d0"
      },
      "source": [
        "# Set your data_dir\n",
        "DATA_DIR='20news-bydate/matlab'\n",
        "# Do not change the code below\n",
        "train_data_dir = os.path.join(DATA_DIR, 'train.data')\n",
        "word_freq_list = create_word_freq_list(train_data_dir=train_data_dir)\n",
        "acc_bernoulli,acc_multi = [],[]\n",
        "recall_bernoulli,recall_multi = [],[]\n",
        "precision_bernoulli,precision_multi = [],[]\n",
        "vsizes = [100,500,1000,2000,5000,20000]\n",
        "print('Bernoulli Model:')\n",
        "for vsize in vsizes:\n",
        "    model_Bernoulli = Naive_Bayes(vsize=vsize, word_freq_list=word_freq_list,data_dir=DATA_DIR,model_type='bernoulli')\n",
        "    model_Bernoulli.train()\n",
        "    acc = model_Bernoulli.test()\n",
        "    acc_bernoulli.append(acc)\n",
        "    print('Vocabulary size: ' + str(vsize) + '\\t Accuracy: ' + str(acc))\n",
        "\n",
        "print('MultiVariate Model:')\n",
        "for vsize in vsizes:\n",
        "    model_MultiVariate = Naive_Bayes(vsize=vsize, word_freq_list=word_freq_list,data_dir=DATA_DIR,model_type='multivariate')\n",
        "    model_MultiVariate.train()\n",
        "    acc = model_MultiVariate.test()\n",
        "    acc_multi.append(acc)\n",
        "    print('Vocabulary size: ' + str(vsize) + '\\t Accuracy: ' + str(acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernoulli Model:\n",
            "Vocabulary size: 100\t Accuracy: 0.07445203656047564\n",
            "Vocabulary size: 500\t Accuracy: 0.173041086165587\n",
            "Vocabulary size: 1000\t Accuracy: 0.2621350607862277\n",
            "Vocabulary size: 2000\t Accuracy: 0.3604578933356997\n",
            "Vocabulary size: 5000\t Accuracy: 0.47697222468719497\n",
            "Vocabulary size: 20000\t Accuracy: 0.5737864939213773\n",
            "MultiVariate Model:\n",
            "Vocabulary size: 100\t Accuracy: 0.2383530038157778\n",
            "Vocabulary size: 500\t Accuracy: 0.5000443695092732\n",
            "Vocabulary size: 1000\t Accuracy: 0.6158487887123968\n",
            "Vocabulary size: 2000\t Accuracy: 0.6800070991214837\n",
            "Vocabulary size: 5000\t Accuracy: 0.7420356730854557\n",
            "Vocabulary size: 20000\t Accuracy: 0.7814357973200816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D82y36aJGoLa"
      },
      "source": [
        "### Evaluation\n",
        "Plot the accuracy, recall and precision following metrics of the two models versus the vocabulary size. Create three plots for each performance metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43LjGyIxGoLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "46499cb7-bb34-4422-e41d-4521f6ff33a1"
      },
      "source": [
        "# Do not change the code in this cell\n",
        "plt.figure()\n",
        "plt.plot(vsizes, acc_bernoulli, label = 'Bernoulli Model')\n",
        "plt.plot(vsizes, acc_multi, label = 'Multinomial Event Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}